import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load multiple datasets
data1 = pd.read_csv('file1.csv')
data2 = pd.read_csv('file2.csv')

# Preprocess datasets
X1 = data1.drop('target_column', axis=1)
y1 = data1['target_column']

X2 = data2.drop('target_column', axis=1)
y2 = data2['target_column']

# Combine datasets
X_combined = pd.concat([X1, X2], axis=0)
y_combined = pd.concat([y1, y2], axis=0)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)

# Normalize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Save preprocessed data for further use
X_train, X_test, y_train, y_test